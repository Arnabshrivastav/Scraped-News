{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSHORTS News Headline\n",
    "\n",
    "url1 = requests.get('https://inshorts.com/en/read/national').text\n",
    "soup1 = BeautifulSoup(url1, 'lxml')\n",
    "\n",
    "for title in soup1.find_all('div',class_='card-stack'):\n",
    "    for heading in soup1.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "\n",
    "url2 = requests.get('https://inshorts.com/en/read/business').text\n",
    "soup2 = BeautifulSoup(url2, 'lxml')\n",
    "\n",
    "for title in soup2.find_all('div',class_='card-stack'):\n",
    "    for heading in soup2.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url3 = requests.get('https://inshorts.com/en/read/world').text\n",
    "soup3 = BeautifulSoup(url3, 'lxml')\n",
    "\n",
    "for title in soup3.find_all('div',class_='card-stack'):\n",
    "    for heading in soup3.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url4 = requests.get('https://inshorts.com/en/read/politics').text\n",
    "soup4 = BeautifulSoup(url4, 'lxml')\n",
    "\n",
    "for title in soup4.find_all('div',class_='card-stack'):\n",
    "    for heading in soup4.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url5 = requests.get('https://inshorts.com/en/read/technology').text\n",
    "soup5 = BeautifulSoup(url5, 'lxml')\n",
    "\n",
    "for title in soup5.find_all('div',class_='card-stack'):\n",
    "    for heading in soup5.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "    \n",
    "url6 = requests.get('https://inshorts.com/en/read/entertainment').text\n",
    "soup6 = BeautifulSoup(url6, 'lxml')\n",
    "\n",
    "for title in soup6.find_all('div',class_='card-stack'):\n",
    "    for heading in soup6.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url7 = requests.get('https://inshorts.com/en/read/automobile').text\n",
    "soup7 = BeautifulSoup(url7, 'lxml')\n",
    "\n",
    "for title in soup7.find_all('div',class_='card-stack'):\n",
    "    for heading in soup7.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "\n",
    "url8 = requests.get('https://inshorts.com/en/read/sports').text\n",
    "soup8 = BeautifulSoup(url8, 'lxml')\n",
    "\n",
    "for title in soup8.find_all('div',class_='card-stack'):\n",
    "    for heading in soup8.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url9 = requests.get('https://inshorts.com/en/read/startup').text\n",
    "soup9 = BeautifulSoup(url9, 'lxml')\n",
    "\n",
    "for title in soup9.find_all('div',class_='card-stack'):\n",
    "    for heading in soup9.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url10 = requests.get('https://inshorts.com/en/read/miscellaneous').text\n",
    "soup10 = BeautifulSoup(url10, 'lxml')\n",
    "\n",
    "for title in soup10.find_all('div',class_='card-stack'):\n",
    "    for heading in soup10.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url11 = requests.get('https://inshorts.com/en/read/hatke').text\n",
    "soup11 = BeautifulSoup(url11, 'lxml')\n",
    "\n",
    "for title in soup11.find_all('div',class_='card-stack'):\n",
    "    for heading in soup11.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)\n",
    "        \n",
    "url12 = requests.get('https://inshorts.com/en/read/science').text\n",
    "soup12 = BeautifulSoup(url12, 'lxml')\n",
    "\n",
    "for title in soup11.find_all('div',class_='card-stack'):\n",
    "    for heading in soup11.find_all('div',class_=\"news-card-title news-right-box\"):\n",
    "        headline=heading.a.span.text\n",
    "        news.append(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE News Headlines\n",
    "\n",
    "url13=requests.get('https://news.google.com/topstories?hl=en-IN&gl=IN&ceid=IN:en').text\n",
    "soup13=BeautifulSoup(url13, 'lxml')\n",
    "           \n",
    "for i in soup13.findAll('a', class_='SFllF'):\n",
    "    x=str(i)\n",
    "    try:\n",
    "        link='https://news.google.com/'+x[x.index('./')+2:x.index('ceid=IN%3Aen')+12]\n",
    "        url=requests.get(link).text\n",
    "        soupx=BeautifulSoup(url13, 'lxml')\n",
    "        for i in ['h3']:\n",
    "            for j in soupx.findAll(i):\n",
    "                news.append(j.text)\n",
    "        for k in ['h4']:\n",
    "            for z in soupx.findAll(i):\n",
    "                news.append(z.text)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOX News Headlines\n",
    "\n",
    "url14 = requests.get('https://www.foxnews.com/').text\n",
    "soup14 = BeautifulSoup(url14, 'lxml')\n",
    "\n",
    "for title in soup14.findAll('h2' or 'h3'):\n",
    "    news.append(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAILYMAIL News Headlines\n",
    "\n",
    "url15 = requests.get('https://www.dailymail.co.uk/home/index.html').text\n",
    "soup15 = BeautifulSoup(url15, 'lxml')\n",
    "\n",
    "for title in soup15.findAll('h2' or 'h3'):\n",
    "    news.append(title.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WASHINGTON POST News Healines\n",
    "\n",
    "url16 = requests.get('https://www.washingtonpost.com/?noredirect=on').text\n",
    "soup16 = BeautifulSoup(url16, 'lxml')\n",
    "\n",
    "for title in soup16.findAll('h2' or 'h3'):\n",
    "    news.append(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABC News Headlines\n",
    "\n",
    "url17 = requests.get('https://abcnews.go.com/').text\n",
    "soup17 = BeautifulSoup(url17, 'lxml')\n",
    "\n",
    "for title in soup17.findAll('div',class_='headlines-li-div'):\n",
    "    news.append(title.h1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBC News Headlines\n",
    "\n",
    "url18 = requests.get('https://www.bbc.com/news').text\n",
    "soup18 = BeautifulSoup(url18, 'lxml')\n",
    "\n",
    "for title in soup18.findAll('div',class_='gel-wrap gs-u-pt+'):\n",
    "    news.append(title.h3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords that have chances to make the news headline viral.\n",
    "# Source of Keywords: \"https://buffer.com/resources/the-most-popular-words-in-most-viral-headlines\"\n",
    "\n",
    "keywords=[\"for\",\"need\",\"wait til you see\",\"will make you\",\"til you see what\",\"how to\",\"when you see\",\"that will make you\",\"til you see\"\n",
    "\"will blow your mind\",\"what happens when\",\"it looks like a\",\"wait til you\",\"you need to know\",\"here are the\",\n",
    "\"what happened to this\",\"you see what\",\"the reason why is\",\"you need to\",\"might look like a\",\"this is what\",\n",
    "\"is what thappens when\",\"that will make\",\"for the first time\",\"what happened\",\"what this guy\",\"what he found is\",\n",
    "\"this guy\",\"what happened to\",\"this is what happens\",\"that will\",\"like a normal\",\"thing i've ever seen\",\n",
    "\"in the world\",\"the definitive ranking of\",\"what he did\",\"look like a normal\",\"looks like a\",\"never\",\"the best\",\n",
    "\"i've ever seen\",\"facebook\",\"make you\",\"how to make\",\"awesome\",\"blow your mind\",\"girl\",\"photos\",\"love\",\"happened\",\n",
    "\"heart\",\"being\",\"something\",\"years\",\"found\",\"seen\",\"actually\",\"valentineâ€™s\",\"down\",\"reasons\",\"watch\",\"need\",\"awesome\",\"media\",\"makes\",\"mind\",\n",
    "\"right\",\"social\",\"beautiful\",\"happened\",\"should\",\"things\",\"little\",\"heart\",\"facebook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANTICIPATION of Virality of the news\n",
    "\n",
    "c=0\n",
    "v=[]\n",
    "viral_headline=[]\n",
    "for i in news:\n",
    "    x=i.split()\n",
    "    for j in keywords:\n",
    "        for k in x:\n",
    "            if k==j:\n",
    "                c+=1\n",
    "                viral_headline.append(i)\n",
    "    v.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset: 8898\n",
      "2580 out of 8898 news headlines are anticipated to be viral\n"
     ]
    }
   ],
   "source": [
    "# Length of DATASET and ANTICIPATED Viral News Headlines\n",
    "\n",
    "\n",
    "print(\"Length of Dataset:\",len(news))\n",
    "print(c,\"out of\",len(news),\"news headlines are anticipated to be viral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Id':range(len(news)), 'News_Headlines':news, 'Viral_Anticipated_News':v})\n",
    "data.to_csv('scrape_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>News_Headlines</th>\n",
       "      <th>Viral_Anticipated_News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No new coronavirus case in 85 districts in 14 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Discussed extending lockdown post May 3 in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>58 active coronavirus cases in Gautam Buddha N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PM said spike in COVID-19 cases could happen i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Appeal to all to support Rajasthan's migrant w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>No. of containment zones down from 1,036 to 80...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Migrant workers are homesick, Centre must arra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Details of procurement of COVID-19 equipment m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>People from Haryana working in Delhi are 'coro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Lakhs and lakhs can't be quarantined by govt: ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Punjab policemen wear badge with name of Harje...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1 cured of COVID-19 discharged, total cases no...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>PM announces COVID warriors website to connect...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Endangered Ganges River Dolphins spotted in Ut...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>FB user says 'PM-backed firm' selling COVID-19...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>60 Indian doctors dance to song 'Happy' amid c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Every 7th doctor in US is Indian and they're w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Won't lose a single rupee: Govt clarifies afte...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>KGMU becomes 1st govt hospital to launch plasm...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>UP CM's 'Agra Model' will turn city into Wuhan...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                     News_Headlines  \\\n",
       "0    0  No new coronavirus case in 85 districts in 14 ...   \n",
       "1    1  Discussed extending lockdown post May 3 in the...   \n",
       "2    2  58 active coronavirus cases in Gautam Buddha N...   \n",
       "3    3  PM said spike in COVID-19 cases could happen i...   \n",
       "4    4  Appeal to all to support Rajasthan's migrant w...   \n",
       "5    5  No. of containment zones down from 1,036 to 80...   \n",
       "6    6  Migrant workers are homesick, Centre must arra...   \n",
       "7    7  Details of procurement of COVID-19 equipment m...   \n",
       "8    8  People from Haryana working in Delhi are 'coro...   \n",
       "9    9  Lakhs and lakhs can't be quarantined by govt: ...   \n",
       "10  10  Punjab policemen wear badge with name of Harje...   \n",
       "11  11  1 cured of COVID-19 discharged, total cases no...   \n",
       "12  12  PM announces COVID warriors website to connect...   \n",
       "13  13  Endangered Ganges River Dolphins spotted in Ut...   \n",
       "14  14  FB user says 'PM-backed firm' selling COVID-19...   \n",
       "15  15  60 Indian doctors dance to song 'Happy' amid c...   \n",
       "16  16  Every 7th doctor in US is Indian and they're w...   \n",
       "17  17  Won't lose a single rupee: Govt clarifies afte...   \n",
       "18  18  KGMU becomes 1st govt hospital to launch plasm...   \n",
       "19  19  UP CM's 'Agra Model' will turn city into Wuhan...   \n",
       "\n",
       "    Viral_Anticipated_News  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "5                        1  \n",
       "6                        2  \n",
       "7                        2  \n",
       "8                        2  \n",
       "9                        2  \n",
       "10                       2  \n",
       "11                       2  \n",
       "12                       2  \n",
       "13                       2  \n",
       "14                       3  \n",
       "15                       3  \n",
       "16                       3  \n",
       "17                       3  \n",
       "18                       4  \n",
       "19                       4  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
